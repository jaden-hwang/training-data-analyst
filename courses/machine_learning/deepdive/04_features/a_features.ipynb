{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4f3CKqFUqL2-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Trying out features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Objectives:**\n",
    "  * Improve the accuracy of a model by adding new features with the appropriate representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is based on 1990 census data from California. This data is at the city block level, so these features reflect the total number of rooms in that block, or the total number of people who live on that block, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6TjLjL9IU80G"
   },
   "source": [
    "## Set Up\n",
    "In this first cell, we'll load the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as estimators\n",
    "import tensorflow.contrib.layers as tflayers\n",
    "from tensorflow.contrib.learn.python.learn.learn_io import pandas_input_fn\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ipRyUHjhU80Q"
   },
   "source": [
    "Next, we'll load our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://storage.googleapis.com/ml_universities/california_housing_train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HzzlSs3PtTmt",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Examine and split the data\n",
    "\n",
    "It's a good idea to get to know your data a little bit before you work with it.\n",
    "\n",
    "We'll print out a quick summary of a few useful statistics on each column.\n",
    "\n",
    "This will include things like mean, standard deviation, max, min, and various quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "gzb10yoVrydW",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, split the data into two parts -- training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(df)) < 0.8\n",
    "traindf = df[msk]\n",
    "evaldf = df[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation\n",
    "\n",
    "In this exercise, we'll be trying to predict median_house_value. It will be our label (sometimes also called a target).\n",
    "\n",
    "We'll modify the feature_cols and input function to represent the features you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import shutil\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as estimators\n",
    "import tensorflow.contrib.layers as tflayers\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "from tensorflow.contrib.learn.python.learn.learn_io import pandas_input_fn\n",
    "\n",
    "def create_feature_cols():\n",
    "  return [\n",
    "    tflayers.real_valued_column('age'),\n",
    "    tflayers.bucketized_column(tflayers.real_valued_column('latitude'), boundaries=np.arange(32.0, 42, 1).tolist()),\n",
    "    tflayers.real_valued_column('num_rooms'),\n",
    "    tflayers.real_valued_column('income')\n",
    "  ]\n",
    "\n",
    "def create_input_fn(df):\n",
    "  def _impl():\n",
    "    features = {\n",
    "      'age' : tf.constant(df['housing_median_age']),\n",
    "      'num_rooms' : tf.constant(df['total_rooms'] / df['households']),\n",
    "      'latitude' : tf.constant(df['latitude']),\n",
    "      'income' : tf.constant(df['median_income']),\n",
    "    }\n",
    "    label = tf.constant(df['median_house_value']/100000) # will talk about why later in the course\n",
    "    return features, label\n",
    "\n",
    "  return _impl\n",
    "\n",
    "\n",
    "def train_and_eval(output_dir):\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    # train and eval input functions\n",
    "    train_input_fn = create_input_fn(traindf)\n",
    "    eval_input_fn = create_input_fn(evaldf)\n",
    "    \n",
    "    def _experiment_fn(output_dir):\n",
    "        # create estimator\n",
    "        model = estimators.LinearRegressor(model_dir=output_dir,\n",
    "                                   feature_columns=create_feature_cols())\n",
    "\n",
    "        experiment = estimators.Experiment(model, \n",
    "            train_input_fn=train_input_fn,\n",
    "            eval_input_fn=eval_input_fn,\n",
    "            #eval_metrics = {'rmse': estimators.MetricSpec(metric_fn=tf.metrics.root_mean_squared_error)},\n",
    "            train_steps=100\n",
    "        )\n",
    "        return experiment\n",
    "    \n",
    "    learn_runner.run(_experiment_fn, output_dir=output_dir)\n",
    "    \n",
    "\n",
    "outdir = './trained_model'\n",
    "shutil.rmtree(outdir, ignore_errors=True)\n",
    "train_and_eval(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "first_steps_with_tensor_flow.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
