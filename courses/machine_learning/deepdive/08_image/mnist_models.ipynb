{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Image Classification with TensorFlow on Cloud ML Engine\n",
    "\n",
    "This notebook demonstrates how to implement different image models on MNIST using Estimator/Experiment. It is a companion to <a href=\"mnist_estimator.ipynb\"> mnist_estimator.ipynb </a> which contains the code for the harness.  The Python package itself is in <a href=\"mnistmodel\">mnistmodel</a>\n",
    "\n",
    "Note the MODEL_TYPE; change it to try out different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "PROJECT = 'cloud-training-demos' # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = 'cloud-training-demos-ml' # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = 'us-central1' # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "MODEL_TYPE='cnn'  # 'linear', 'dnn', 'dnn_dropout', etc.\n",
    "\n",
    "# do not change these\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['MODEL_TYPE'] = MODEL_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model functions\n",
    "\n",
    "Here are the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear\n",
    "A simple low-level matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# linear\n",
    "def linear_model(img, mode):\n",
    "  X = tf.reshape(img, [-1, HEIGHT*WIDTH]) # flattened\n",
    "  #W = tf.Variable(tf.zeros([HEIGHT*WIDTH, NCLASSES]))\n",
    "  #b = tf.Variable(tf.zeros([NCLASSES]))\n",
    "  W = tf.Variable(tf.truncated_normal([HEIGHT*WIDTH, NCLASSES], stddev=0.1))\n",
    "  b = tf.Variable(tf.truncated_normal([NCLASSES], stddev=0.1))\n",
    "  ylogits = tf.matmul(X, W) + b\n",
    "  return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network\n",
    "\n",
    "A 3-hidden layer network that uses tf.layers to reduce the boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dnn\n",
    "def dnn_model(img, mode):\n",
    "  X = tf.reshape(img, [-1, HEIGHT*WIDTH]) # flattened\n",
    "  h1 = tf.layers.dense(X, 300, activation=tf.nn.relu)\n",
    "  h2 = tf.layers.dense(h1,100, activation=tf.nn.relu)\n",
    "  h3 = tf.layers.dense(h2, 30, activation=tf.nn.relu)\n",
    "  ylogits = tf.layers.dense(h3, NCLASSES, activation=None)\n",
    "  return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN with dropout\n",
    "\n",
    "A 3-hidden layer network with a dropout layer between layer 3 and the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def dnn_dropout_model(img, mode):\n",
    "  X = tf.reshape(img, [-1, HEIGHT*WIDTH]) # flattened\n",
    "  h1 = tf.layers.dense(X, 300, activation=tf.nn.relu)\n",
    "  h2 = tf.layers.dense(h1,100, activation=tf.nn.relu)\n",
    "  h3 = tf.layers.dense(h2, 30, activation=tf.nn.relu)\n",
    "  h3d = tf.layers.dropout(h3, rate=0.1, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "  ylogits = tf.layers.dense(h3d, NCLASSES, activation=None)\n",
    "  return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "2 convolutional layers, both wrapped into maxpool layers, followed by a dense layer and then a dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def cnn_model(img, mode):\n",
    "  X = tf.reshape(img, [-1, HEIGHT, WIDTH, 1]) # as a 2D image with one grayscale channel\n",
    "  c1 = tf.layers.max_pooling2d(\n",
    "         tf.layers.conv2d(X, filters=10,\n",
    "                          kernel_size=5, strides=1, # ?x28x28x10\n",
    "                          padding='same', activation=tf.nn.relu), \n",
    "         pool_size=2, strides=2\n",
    "       ) # ?x14x14x10\n",
    "  c2 = tf.layers.max_pooling2d(\n",
    "         tf.layers.conv2d(c1, filters=20,\n",
    "                          kernel_size=5, strides=1, \n",
    "                          padding='same', activation=tf.nn.relu),\n",
    "         pool_size=2, strides=2\n",
    "       ) # ?x7x7x20\n",
    "  outlen = (HEIGHT//4)*(WIDTH//4)*20 # integer division; 980\n",
    "  c2flat = tf.reshape(c2, [-1, outlen]) # flattened\n",
    "  h3 = tf.layers.dense(c2flat, 300, activation=tf.nn.relu)\n",
    "  h3d = tf.layers.dropout(h3, rate=0.25, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "  ylogits = tf.layers.dense(h3d, NCLASSES, activation=None)\n",
    "  return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN with batchnorm\n",
    "\n",
    "With batch normalization, and using hyperparameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model(img, mode, hparams):\n",
    "  ksize1 = hparams.get('ksize1', 5)\n",
    "  ksize2 = hparams.get('ksize2', 5)\n",
    "  nfil1 = hparams.get('nfil1', 10)\n",
    "  nfil2 = hparams.get('nfil2', 20)\n",
    "  dprob = hparams.get('dprob', 0.25)\n",
    "\n",
    "  X = tf.reshape(img, [-1, HEIGHT, WIDTH, 1]) # as a 2D image with one grayscale channel\n",
    "  c1 = tf.layers.max_pooling2d(\n",
    "         tf.layers.conv2d(X, filters=nfil1,\n",
    "                          kernel_size=ksize1, strides=1, # ?x28x28x10\n",
    "                          padding='same', activation=tf.nn.relu),\n",
    "         pool_size=2, strides=2\n",
    "       ) # ?x14x14x10\n",
    "  c2 = tf.layers.max_pooling2d(\n",
    "         tf.layers.conv2d(c1, filters=nfil2,\n",
    "                          kernel_size=ksize2, strides=1, \n",
    "                          padding='same', activation=tf.nn.relu),\n",
    "         pool_size=2, strides=2\n",
    "       ) # ?x7x7x20\n",
    "\n",
    "  outlen = (HEIGHT//4)*(WIDTH//4)*nfil2 # integer division; 980\n",
    "  c2flat = tf.reshape(c2, [-1, outlen]) # flattened\n",
    "\n",
    "  if hparams['batch_norm']:\n",
    "    h3 = tf.layers.dense(c2flat, 300, activation=None)\n",
    "    h3 = tf.layers.batch_normalization(h3, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    h3 = tf.nn.relu(h3)\n",
    "  else:  \n",
    "    h3 = tf.layers.dense(c2flat, 300, activation=tf.nn.relu)\n",
    "\n",
    "  h3d = tf.layers.dropout(h3, rate=dprob, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "  ylogits = tf.layers.dense(h3d, NCLASSES, activation=None)\n",
    "\n",
    "  if hparams['batch_norm']:\n",
    "     ylogits = tf.layers.batch_normalization(ylogits, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "  return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run as a Python module\n",
    "\n",
    "Let's run it as Python module.  Note the --model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: task.py [-h] [--train_batch_size TRAIN_BATCH_SIZE]\n",
      "               [--learning_rate LEARNING_RATE] [--train_steps TRAIN_STEPS]\n",
      "               --output_dir OUTPUT_DIR --model MODEL [--job-dir JOB_DIR]\n",
      "               [--ksize1 KSIZE1] [--ksize2 KSIZE2] [--nfil1 NFIL1]\n",
      "               [--nfil2 NFIL2] [--dprob DPROB] [--batch_norm]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --train_batch_size TRAIN_BATCH_SIZE\n",
      "                        Batch size for training steps\n",
      "  --learning_rate LEARNING_RATE\n",
      "                        Initial learning rate for training\n",
      "  --train_steps TRAIN_STEPS\n",
      "                        Steps to run the training job for. A step is one\n",
      "                        batch-size,\n",
      "  --output_dir OUTPUT_DIR\n",
      "                        GCS location to write checkpoints and export models\n",
      "  --model MODEL         Type of model. Supported types are ['cnn',\n",
      "                        'dnn_dropout', 'dnn', 'linear']\n",
      "  --job-dir JOB_DIR     this model ignores this field, but it is required by\n",
      "                        gcloud\n",
      "  --ksize1 KSIZE1       kernel size of first layer for CNN\n",
      "  --ksize2 KSIZE2       kernel size of second layer for CNN\n",
      "  --nfil1 NFIL1         number of filters in first layer for CNN\n",
      "  --nfil2 NFIL2         number of filters in second layer for CNN\n",
      "  --dprob DPROB         dropout probability for CNN\n",
      "  --batch_norm          if specified, do batch_norm for CNN\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "rm -rf mnistmodel.tar.gz mnist_trained\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/mnistmodel\n",
    "#python -m trainer.task \\\n",
    "#   --output_dir=${PWD}/mnist_trained \\\n",
    "#   --train_steps=10 --learning_rate=0.01 --model=$MODEL_TYPE --job-dir=./tmp\n",
    "python -m trainer.task --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do it on ML Engine. Note the --model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "OUTDIR=gs://${BUCKET}/mnist/trained_${MODEL_TYPE}\n",
    "JOBNAME=mnist_${MODEL_TYPE}_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${PWD}/mnistmodel/trainer \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=BASIC_GPU \\\n",
    "   --runtime-version=1.2 \\\n",
    "   -- \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --train_steps=10000 --learning_rate=0.01 --train_batch_size=512 \\\n",
    "   --model=$MODEL_TYPE --batch_norm\n",
    "    \n",
    "#--nfil1=16 --nfil2=18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are my results:\n",
    "\n",
    "Model | Accuracy | Time taken | Model description | Run time parameters\n",
    "--- | :---: | ---\n",
    "linear | 91.53 | 3 min | | 100 steps, LR=0.01, Batch=512\n",
    "linear | 92.73 | 8 min | | 1000 steps, LR=0.01, Batch=512\n",
    "linear | 92.29 | 18 min | | 10000 steps, LR=0.01, Batch=512\n",
    "dnn | 98.14 | 15 min | 300-100-30 nodes fully connected | 10000 steps, LR=0.01, Batch=512\n",
    "dnn | 97.99 | 48 min | 300-100-30 nodes fully connected | 100000 steps, LR=0.01, Batch=512\n",
    "dnn_dropout | 97.84 | 29 min | 300-100-30-DL(0.1)- nodes | 20000 steps, LR=0.01, Batch=512\n",
    "cnn | 98.97 | 35 min | maxpool(10 5x5 cnn, 2)-maxpool(20 5x5 cnn, 2)-300-DL(0.25) | 20000 steps, LR=0.01, Batch=512\n",
    "cnn | 98.93 | 35 min | maxpool(10 11x11 cnn, 2)-maxpool(20 3x3 cnn, 2)-300-DL(0.25) | 20000 steps, LR=0.01, Batch=512\n",
    "cnn | 99.17 | 35 min | maxpool(10 11x11 cnn, 2)-maxpool(20 3x3 cnn, 2)-300-DL(0.25), batch_norm (logits only) | 20000 steps, LR=0.01, Batch=512\n",
    "cnn | 99.27 | 35 min | maxpool(10 11x11 cnn, 2)-maxpool(20 3x3 cnn, 2)-300-DL(0.25), batch_norm (logits, deep) | 10000 steps, LR=0.01, Batch=512\n",
    "cnn | 99.48 | 12 hr | as-above but nfil1=20, nfil2=27, dprob=0.1, lr=0.001, batchsize=233 | (hyperparameter optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DO NOT RUN anything beyond this point\n",
    "\n",
    "This shows you what I did, but trying to repeat this will take several hours.\n",
    "\n",
    "<br/>\n",
    "\n",
    "## Hyperparameter tuning\n",
    "\n",
    "The key thing is here the --config parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingInput:\r\n",
      "  scaleTier: CUSTOM\r\n",
      "  masterType: complex_model_m_gpu\r\n",
      "  hyperparameters:\r\n",
      "    goal: MAXIMIZE\r\n",
      "    maxTrials: 30\r\n",
      "    maxParallelTrials: 2\r\n",
      "    hyperparameterMetricTag: accuracy\r\n",
      "    params:\r\n",
      "    - parameterName: train_batch_size\r\n",
      "      type: INTEGER\r\n",
      "      minValue: 32\r\n",
      "      maxValue: 512\r\n",
      "      scaleType: UNIT_LINEAR_SCALE\r\n",
      "    - parameterName: learning_rate\r\n",
      "      type: DOUBLE\r\n",
      "      minValue: 0.001\r\n",
      "      maxValue: 0.1\r\n",
      "      scaleType: UNIT_LOG_SCALE\r\n",
      "    - parameterName: nfil1\r\n",
      "      type: INTEGER\r\n",
      "      minValue: 5\r\n",
      "      maxValue: 20\r\n",
      "      scaleType: UNIT_LINEAR_SCALE\r\n",
      "    - parameterName: nfil2\r\n",
      "      type: INTEGER\r\n",
      "      minValue: 10\r\n",
      "      maxValue: 30\r\n",
      "      scaleType: UNIT_LINEAR_SCALE\r\n",
      "    - parameterName: dprob\r\n",
      "      type: DOUBLE\r\n",
      "      minValue: 0.1\r\n",
      "      maxValue: 0.6\r\n",
      "      scaleType: UNIT_LINEAR_SCALE\r\n"
     ]
    }
   ],
   "source": [
    "!cat hyperparam.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes <b>13 hours and 250 ML Units</b>, so don't try this at home :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "OUTDIR=gs://${BUCKET}/mnist/trained_${MODEL_TYPE}_hparam\n",
    "JOBNAME=mnist_${MODEL_TYPE}_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${PWD}/mnistmodel/trainer \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --runtime-version=1.2 \\\n",
    "   --config hyperparam.yaml \\\n",
    "   -- \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --model=$MODEL_TYPE --batch_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring training with TensorBoard\n",
    "\n",
    "Use this cell to launch tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('gs://{}/mnist/trained_{}'.format(BUCKET, MODEL_TYPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "  TensorBoard().stop(pid)\n",
    "  print 'Stopped TensorBoard with pid {}'.format(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what it looks like with a linear model for 10,000 steps:\n",
    "<img src=\"images/eval_linear_10000.png\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying and predicting with model\n",
    "\n",
    "Deploy the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "MODEL_NAME=\"mnist\"\n",
    "MODEL_VERSION=${MODEL_TYPE}\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/mnist/trained_${MODEL_TYPE}/export/Servo | tail -1)\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict with the model, let's take one of the example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json, codecs\n",
    "import matplotlib.pyplot as plt\n",
    "IMGNO=5\n",
    "jsondata = {'image': [mnist.test.images[IMGNO].reshape(HEIGHT, WIDTH).tolist()]}\n",
    "json.dump(jsondata, codecs.open('test.json', 'w', encoding='utf-8'))\n",
    "plt.imshow(mnist.test.images[IMGNO].reshape(HEIGHT, WIDTH));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send it to the prediction service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%bash\n",
    "gcloud ml-engine predict --model=mnist --version=${MODEL_TYPE} --json-instances=./test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "# Copyright 2017 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
